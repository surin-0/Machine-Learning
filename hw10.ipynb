{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:54:48.508891Z",
     "start_time": "2020-06-07T06:54:48.247497Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Moon Jeong-Hyeon \nlast updated: 2020-06-21 \n\nnumpy 1.18.1\npandas 1.0.2\nmatplotlib 3.1.3\nsklearn 0.0\n"
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Moon Jeong-Hyeon' -u -d -p numpy,pandas,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** 코딩해야할 부분을 제외하고는 수정하지 마세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, ssl\n",
    "# if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "#     getattr(ssl, '_create_unverified_context', None)): \n",
    "#     ssl._create_default_https_context = ssl._create_unverified_context  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:03.109724Z",
     "start_time": "2020-06-07T06:54:49.615474Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_sci = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:03.494027Z",
     "start_time": "2020-06-07T06:55:03.117550Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train_, y_test_ = train_test_split(mnist_sci.data, mnist_sci.target, \n",
    "                                                    test_size = 0.1,\n",
    "                                                   shuffle = True)\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "x_train = x_train.reshape(-1,1,28,28)\n",
    "x_test = x_test.reshape(-1,1,28,28)\n",
    "\n",
    "def one_hoy_label(X):\n",
    "    T = np.zeros((X.size, 10))    \n",
    "    for idx, row in enumerate(T):\n",
    "        row[int(X[idx])] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "y_train = one_hoy_label(y_train_)\n",
    "y_test = one_hoy_label(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_CE:\n",
    "    \"\"\"\n",
    "    편의를 위해서 softmax와 crossenropy를 결합한 것입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실함수\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = CE_loss(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1 에서 구현한 것을 바탕으로 CNN도 적용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x.T\n",
    "    x = x-np.max(x, axis=0)\n",
    "    y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "    return y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE_loss(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    ce = -np.sum(t*np.log(y))\n",
    "    ce /= batch_size\n",
    "    return ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x<=0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FClayer:\n",
    "    def __init__(self, W, b):\n",
    "        \n",
    "        self.W = W\n",
    "        self.b = b \n",
    "        self.x = None\n",
    "\n",
    "        self.original_x_shape = None\n",
    "        \n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        dx = dx.reshape(*self.original_x_shape)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW10 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x_train[0:100]\n",
    "b1 = 0.01 * np.random.randn(3, 1, 3, 3)\n",
    "c1 = np.zeros(3)\n",
    "\n",
    "b2 = 0.01 * np.random.randn(int(3 * (26/2) * (26/2)), 16)\n",
    "c2 = np.zeros(16)\n",
    "\n",
    "b3 = 0.01 * np.random.randn(16, 10)\n",
    "c3 = np.zeros(10)\n",
    "\n",
    "# network = SimpleConvNet(input_dim=(1,28,28), \n",
    "#                         conv_param = {'filter_num': 3, 'filter_size': 3, 'pad': 0, 'stride': 1},\n",
    "#                         hidden_size=16, output_size=10)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(100, 3, 26, 26)"
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "source": [
    "conv_layer = Conv(b1, c1, stride = 1 , pad = 0)\n",
    "out = conv_layer.forward(a)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(100, 3, 26, 26)"
     },
     "metadata": {},
     "execution_count": 153
    }
   ],
   "source": [
    "r = Relu()\n",
    "out = r.forward(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(100, 3, 13, 13)"
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "m = MaxPooling(pool_h = 2, pool_w = 2, stride = 2)\n",
    "out = m.forward(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(100, 16)"
     },
     "metadata": {},
     "execution_count": 155
    }
   ],
   "source": [
    "fc1_layer = FClayer(b2, c2)\n",
    "fc_out = fc1_layer.forward(out)\n",
    "fc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2.302586271546324"
     },
     "metadata": {},
     "execution_count": 156
    }
   ],
   "source": [
    "r2 = Relu()\n",
    "relu2_out = r2.forward(fc_out)\n",
    "\n",
    "fc2_layer = FClayer(b3, c3)\n",
    "fc2_out = fc2_layer.forward(relu2_out)\n",
    "\n",
    "sce = Softmax_CE()\n",
    "loss = sce.forward(fc2_out, y_train[:100])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(100, 3, 13, 13)"
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "source": [
    "dout = sce.backward(1)\n",
    "dout = fc2_layer.backward(dout)\n",
    "dout = r2.backward(dout)\n",
    "dout = fc1_layer.backward(dout)\n",
    "dout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(100, 3, 26, 26)"
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "dout_pooling = m.backward(dout)\n",
    "dout_relu1 = r.backward(dout_pooling)\n",
    "dout_relu1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(100, 1, 28, 28)"
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "dout_conv = conv_layer.backward(dout_relu1)\n",
    "dout_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = {}\n",
    "grads['W1'], grads['b1'] = b1, c1\n",
    "grads['W2'], grads['b2'] = b2, c2\n",
    "grads['W3'], grads['b3'] = b3, c3\n",
    "\n",
    "new_grads = {}\n",
    "new_grads['W1'], new_grads['b1'] = conv_layer.dW, conv_layer.db\n",
    "new_grads['W2'], new_grads['b2'] = fc1_layer.dW, fc1_layer.db\n",
    "new_grads['W3'], new_grads['b3'] = fc2_layer.dW, fc2_layer.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv():\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None   \n",
    "        \n",
    "        # 가중치와 편향 매개변수의 기울기\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "        self.out_h = None\n",
    "        self.out_w = None\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # backward 의 shape 확인을 위해서 저장\n",
    "        self.x = x[:]        \n",
    "        \n",
    "        FN, C_, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        # output 출력 shape \n",
    "        self.out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        self.out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "        out_h = self.out_h\n",
    "        out_w = self.out_w        \n",
    "        \n",
    "        # padding\n",
    "        pad_x = np.pad(\n",
    "            x, \n",
    "            ((0, 0), (0, 0), (self.pad, self.pad), (self.pad, self.pad)), \n",
    "            \"constant\", constant_values=0\n",
    "        )        \n",
    "        out = np.zeros((N, FN, out_h, out_w))        \n",
    "        for n in range(N):\n",
    "            for f in range(FN):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-1-1 forward를 구현 하세요                                   #\n",
    "                        ######################################################################\n",
    "                        result = pad_x[n, :, j*self.stride : j*self.stride+FH, \n",
    "                            i*self.stride : i*self.stride + FW] * self.W[f]\n",
    "                        out[n][f][j][i] += np.sum(result) + self.b[f]\n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = self.x.shape\n",
    "        \n",
    "        out_h = self.out_h\n",
    "        out_w = self.out_w\n",
    "        \n",
    "        # padding\n",
    "        pad_x = np.pad(\n",
    "            self.x, \n",
    "            ((0, 0), (0, 0), (self.pad, self.pad), (self.pad, self.pad)), \n",
    "            \"constant\", constant_values=0\n",
    "        )\n",
    "        \n",
    "        dx = np.zeros(pad_x.shape)\n",
    "        dw = np.zeros(self.W.shape)\n",
    "        db = np.zeros(self.b.shape)\n",
    "\n",
    "        for n in range(N):\n",
    "            for f in range(FN):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-1-2 backward 구현 하세요                                    #\n",
    "                        ######################################################################\n",
    "                        dw[f] += pad_x[n, : , j* self.stride : j*self.stride + FH, \n",
    "                            i*self.stride: i*self.stride + FW] * dout[n][f][j][i]\n",
    "                        dx[n, :, j*self.stride: j*self.stride + FH, \n",
    "                            i*self.stride: i*self.stride + FW] += self.W[f] * dout[n, f, j, i]\n",
    "                db[f] = np.sum(dout[n,f,:,:])\n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################\n",
    "        # remove padding\n",
    "        dx = dx[:, :, self.pad:dx.shape[2]-self.pad, self.pad:dx.shape[3]-self.pad]\n",
    "        \n",
    "        self.db = db\n",
    "        self.dW = dw\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x[:]\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        out = np.zeros((N, C, out_h, out_w))\n",
    "        for j in range(out_h):\n",
    "            for i in range(out_w):\n",
    "                ######################################################################\n",
    "                # 문제 2-2-1 forward를 구현 하세요                                   #\n",
    "                ######################################################################\n",
    "                out[:, :, j, i] = np.max(self.x[:, :, j*self.stride : j*self.stride + self.pool_h, \n",
    "                    i*self.stride : i*self.stride + self.pool_w])\n",
    "                ######################################################################\n",
    "                #                          END OF YOUR CODE                          #\n",
    "                ######################################################################\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \n",
    "        N, C, H, W = self.x.shape\n",
    "        out_h = (H-self.pool_h) // self.stride + 1\n",
    "        out_w = (W-self.pool_w) // self.stride + 1\n",
    "\n",
    "        dx = np.zeros(self.x.shape)\n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-2-2 backward를 구현 하세요                                  #\n",
    "                        ######################################################################   \n",
    "                        arr = self.x[n, c, j*self.stride: j*self.stride + self.pool_h, \n",
    "                            i*self.stride : i*self.stride + self.pool_w]\n",
    "                        idx = np.nanargmax(arr)\n",
    "                        (a, b) = np.unravel_index(idx, arr.shape)\n",
    "                        dx[n][c][j*self.stride + a][i*self.stride + b] = dout[n][c][j][i]\n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:19.163192Z",
     "start_time": "2020-06-07T06:55:19.146865Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        weight_init_std = 0.01\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        \n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        \n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Conv(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = MaxPooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['FClayer1'] = FClayer(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['FClayer2'] = FClayer(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = Softmax_CE()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        ######################################################################\n",
    "        #  2-3 해당 주어진 gradient 함수에 주석을 다세요                     #\n",
    "        ######################################################################\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # loss 함수에서 predict 함수를 호출한다.\n",
    "        # predict 함수 내에서 각 layer의 foward을 순서대로 진행하여\n",
    "        # 하나의 forward prop이 끝난 에측값을 loss 함수에 return 한다.\n",
    "        # loss 함수는 softmax_CE의 forward 함수를 호출하여 loss를 계산한다. \n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        # softmax_CE의 backward 함수를 호출하여\n",
    "        # 전파하는 값을 배치의 수로 나눈 결과, 즉 데이터 1개당 오차를 return 받는다.\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        # forward prop과 반대 방향으로 backward prop을 진행해야 하기 때문에 \n",
    "        # layers의 순서를 뒤집는다.\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        # 각 layer의 backward를 진행하여 dout을 갱신한다.\n",
    "        # back propagation은 끝에서부터 미분값을 곱해나가는 구조이기 때문에\n",
    "        # 다음 layer의 input으로 그 전 layer의 output인 dout을 다시 넣어주는 recursive한 형태이다.\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['FClayer1'].dW, self.layers['FClayer1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['FClayer2'].dW, self.layers['FClayer2'].db\n",
    "        # 각 layer의 gradient값을 grads 객체 안에 저장하여 갱신할 매개변수들을 return 한다.\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:20.334140Z",
     "start_time": "2020-06-07T06:55:20.301677Z"
    }
   },
   "outputs": [],
   "source": [
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 3, 'filter_size': 3, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=16, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습이 되기전 conv layer 의 파라미터값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 3 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"69.636527pt\" version=\"1.1\" viewBox=\"0 0 178.283234 69.636527\" width=\"178.283234pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 69.636527 \nL 178.283234 69.636527 \nL 178.283234 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 10.7 58.936527 \nL 62.436527 58.936527 \nL 62.436527 7.2 \nL 10.7 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p9d059378b7)\">\n    <image height=\"52\" id=\"imageddb8f14b79\" transform=\"scale(1 -1)translate(0 -52)\" width=\"52\" x=\"10.7\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAADQAAAA0CAYAAADFeBvrAAAABHNCSVQICAgIfAhkiAAAAI1JREFUaIHt10ENRSEMBdH255lACaJRgQM26OGLKIsJmSPgphNW5FrrRNHeuzoRERFzzvLG78IdKAbRGURnEJ1BdAbRGURnEN1zQXnOKX/wMvPGLVc890IG0RlEZxCdQXQG0RlEZxCdQXTfGKM80lq7cEpE77288dwLGURnEJ1BdAbRGURnEJ1BdM8F/QEx5g+KnNAVwwAAAABJRU5ErkJggg==\" y=\"-6.936527\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\"/>\n   <g id=\"matplotlib.axis_2\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 10.7 58.936527 \nL 10.7 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 62.436527 58.936527 \nL 62.436527 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 10.7 58.936527 \nL 62.436527 58.936527 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 10.7 7.2 \nL 62.436527 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 65.023353 58.936527 \nL 116.75988 58.936527 \nL 116.75988 7.2 \nL 65.023353 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p8589fbabb5)\">\n    <image height=\"52\" id=\"image9a6e7d2aa5\" transform=\"scale(1 -1)translate(0 -52)\" width=\"52\" x=\"65.023353\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAADQAAAA0CAYAAADFeBvrAAAABHNCSVQICAgIfAhkiAAAAJVJREFUaIHt10ENBCEQBdGezRoAD4hBCKo4YwFLyNgV0XOokCoBP/3Ciaf3/otke+/sRERElFLSG58X7kAliJ4geoLoCaIniJ4geoLoXQd6xhjpD945541botaa3rjuhQTRE0RPED1B9ATRE0RPED1B9L6ttfTInPOFUyLWWumN615IED1B9ATRE0RPED1B9ATRuw70BwksDeDHS4KfAAAAAElFTkSuQmCC\" y=\"-6.936527\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\"/>\n   <g id=\"matplotlib.axis_4\"/>\n   <g id=\"patch_8\">\n    <path d=\"M 65.023353 58.936527 \nL 65.023353 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 116.75988 58.936527 \nL 116.75988 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 65.023353 58.936527 \nL 116.75988 58.936527 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 65.023353 7.2 \nL 116.75988 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g id=\"patch_12\">\n    <path d=\"M 119.346707 58.936527 \nL 171.083234 58.936527 \nL 171.083234 7.2 \nL 119.346707 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p2f827a33d7)\">\n    <image height=\"52\" id=\"image0f35ee94ef\" transform=\"scale(1 -1)translate(0 -52)\" width=\"52\" x=\"119.346707\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAADQAAAA0CAYAAADFeBvrAAAABHNCSVQICAgIfAhkiAAAAJFJREFUaIHt17ENRCEMwNBwLUuwM2tRsAFT0ND8GyIUFvIbIIqVKmWt9UVSay07IiIi5pzpGb8Le6AYRGcQnUF0BtEZRGcQnUF0zwWVvXf6wau13tgleu/pGc9dyCA6g+gMojOIziA6g+gMojOIrowx0h/r3vvGLnHOSc947kIG0RlEZxCdQXQG0RlEZxDdc0F/VtsVugGUNT4AAAAASUVORK5CYII=\" y=\"-6.936527\"/>\n   </g>\n   <g id=\"matplotlib.axis_5\"/>\n   <g id=\"matplotlib.axis_6\"/>\n   <g id=\"patch_13\">\n    <path d=\"M 119.346707 58.936527 \nL 119.346707 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 171.083234 58.936527 \nL 171.083234 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 119.346707 58.936527 \nL 171.083234 58.936527 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 119.346707 7.2 \nL 171.083234 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9d059378b7\">\n   <rect height=\"51.736527\" width=\"51.736527\" x=\"10.7\" y=\"7.2\"/>\n  </clipPath>\n  <clipPath id=\"p8589fbabb5\">\n   <rect height=\"51.736527\" width=\"51.736527\" x=\"65.023353\" y=\"7.2\"/>\n  </clipPath>\n  <clipPath id=\"p2f827a33d7\">\n   <rect height=\"51.736527\" width=\"51.736527\" x=\"119.346707\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALIAAABFCAYAAADuHbzJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACRUlEQVR4nO3dMYoiURRG4VvDBIIgVlCJyWDoClyBmakmLsLMFRiYuwQxFSPBTHegsYGImjidqijim6SrmaANilvTM/Nzvkiw761XcBCD6u4ohGDA/+7b3z4AkAdChgRChgRChgRChgRChoTvWX64VCqFJElcF9zv9675VLFYdM1fLhe73W7R+64Qx7Fr3/F4dM2nqtWqe8d2u30LISTlcjlUKhXXrufz6T5PXns2m81bCOHTADOFnCSJDQYD12G63a5rPlWv113zi8Xi43Ucx+5z9Xo913yq3++7d3Q6nZ2ZWaVSsdFo5Np1Pp/d5zEzu9/v7h2NRmP36j2+WkACIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUNCpsc44zi2VqvlumC73XbNp6bTaS57zMxut5ttNhvXjmazmctZ5vN5LnvMzAqFgtVqNdcO73PfqeFwmMueV/hEhgRChgRChgRChgRChgRChgRChgRChgRChgRChgRChgRChgRChgRChgRChgRChgRChoRMvyFyvV5tvV67Ljgej13zqeVy6ZqfTCYfr+/3ux0OB9e+2Wzmmk95/3L+7x6Ph51OJ9eOvP6h6Gq1ymXPK3wiQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQwIhQ0KU5cHpKIp+mtnuzx3nS/0IISRmcvdl9n5vqvf12RuZQgb+VXy1gARChgRChgRChgRChgRChgRChgRChgRChoRf3r1/gkUohYYAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1608745\n2.2947127369810967\n2.3039757984220652\n2.3023981812629275\n2.300281687977349\n2.2992478412044606\n2.3022684121700023\n2.3093818492798035\n2.2965643165191043\n2.307938371848641\n2.3000401976466964\n2.301830393277782\n2.296881165206944\n2.306703175714371\n2.305298492380674\n2.305690216654577\n2.3050447151891613\n2.3010853226693357\n2.3073136111619506\n2.299754418745842\n2.2949917693356197\n2.297643413183891\n2.3075672031862755\n2.2959211587234085\n2.29815971966851\n2.2973674438910017\n2.3016093140115923\n2.302680317972454\n2.30946334095803\n2.3111936408275375\n2.3029186083129973\n2.2998996215489638\n2.29437032246162\n2.3010864076036435\n2.3016873641817286\n2.3062916411630794\n2.3012807108722186\n2.299242056437366\n2.3025054848117863\n2.2957967081661645\n2.2955333897046817\n2.2996526044261567\n2.303698124989282\n2.3028338511044146\n2.2994624302349638\n2.2883140418873937\n2.29430222298086\n2.3047564627941046\n2.297976959889409\n2.2966788649526144\n2.301992901725944\n2.297120212328699\n2.304590356280156\n2.2942514846159514\n2.3084788181705806\n2.3099753476691745\n2.2941797474059116\n2.3015989373432357\n2.3052053897265483\n2.299191919286302\n2.3046510894673418\n2.3015041101567433\n2.2936569094002928\n2.2979980210754367\n2.301857469375528\n2.305158752769684\n2.300795692315029\n2.2990005711851795\n2.297748835419757\n2.3058017142445992\n2.297881671499482\n2.304536396416595\n2.2952944251958742\n2.2975669594203096\n2.3052360036377713\n2.3023224967058904\n2.305261091419254\n2.2970801419905706\n2.2946946567496367\n2.300437599722893\n2.297514124273164\n2.30345834608887\n2.305714529197542\n2.2852320075785815\n2.294368854434055\n2.3094796107145665\n2.3032197138647574\n2.296028642738952\n2.303881166979417\n2.3011339758905267\n2.299080241937659\n2.2936165246415725\n2.2989223338913694\n2.30563019639821\n2.3077694119479775\n2.3035356008761814\n2.3016256220084332\n2.305860065011574\n2.3051166531584575\n2.303394826236445\n2.3011076608857337\n2.297531900119344\n2.3016500024053084\n2.29819272796528\n2.297563691417209\n2.303292119426177\n2.2911542453940617\n2.297213186196671\n2.3048528310799252\n2.302121666671965\n2.2923125924915215\n2.3099791634254103\n2.302021428123394\n2.3043770961126064\n2.309497167288006\n2.2950459213897485\n2.299757873589601\n2.2949023666204997\n2.2970968221782413\n2.3004840211925277\n2.305392719072119\n2.3011236209933323\n2.3051316429751374\n2.2972027222794265\n2.292058398925455\n2.3048267851817967\n2.2947894888192586\n2.3055027409891413\n2.3021504542114615\n2.298679852423165\n2.2986039878287774\n2.296959914571729\n2.293784218367427\n2.292409884629136\n2.2970542041887887\n2.3105868821127067\n2.2979555544052443\n2.3079580362292145\n2.299256859438383\n2.292222373220322\n2.306124754619781\n2.3000406188787537\n2.3064486910597712\n2.300282342215543\n2.3022267393257754\n2.2893785889749494\n2.302256181365654\n2.290644422244534\n2.286235690933596\n2.2980677313444633\n2.293736786781362\n2.3013270609179024\n2.2996076058400705\n2.305193726703051\n2.3044130425009097\n2.291961002986872\n2.3062975670130696\n2.2988741077606996\n2.3143258447666066\n2.283421881041906\n2.2972835172702513\n2.3025266183131414\n2.305847397460356\n2.2909127133870366\n2.3030081483686655\n2.292739817708013\n2.294520630251769\n2.2873998335963126\n2.296348047396709\n2.3046575382443764\n2.303627488863205\n2.3089894133924975\n2.3047946298925215\n2.292398190573571\n2.2930111984274086\n2.2992804645594007\n2.302052931319315\n2.305141205242596\n2.30426806338314\n2.3003579595288146\n2.2881799086398273\n2.2962895823070046\n2.2955259371065404\n2.3066302633707663\n2.3050397486760503\n2.3019081702613535\n2.295053791570902\n2.3053049156743266\n2.293424639206323\n2.3054523332434367\n2.3110153840538987\n2.292085270476302\n2.3032015692365255\n2.302015813708886\n2.300186206464436\n2.306040184122629\n2.2988741604961858\n2.283671355987442\n2.30701780138732\n2.3146383469684757\n2.307452850516919\n2.299991235459002\n2.2968500457625733\n2.2943889636861856\n2.295894891077117\n2.2930845413574765\n2.2863440349884097\n2.311308603118214\n2.306529872506377\n2.2986657727139703\n2.2957904648494925\n2.3009306151957434\n2.301570602065718\n2.2907309762311523\n2.3044646141738205\n2.3002591315606917\n2.308348535228499\n2.2947747403004883\n2.3040695159619644\n2.29754501798373\n2.3068631934773105\n2.3016685285553837\n2.3018613667140504\n2.300990671287064\n2.301989910622909\n2.2970865435834513\n2.309301289855006\n2.292086292445839\n2.302970246531755\n2.2988176856278444\n2.2993691416771487\n2.3000774401902233\n2.2942466849564522\n2.3071541527361874\n2.2998975693624115\n2.29343974778613\n2.2995713804798528\n2.2981849153365017\n2.289960025789155\n2.2977517307239794\n2.308968991662726\n2.301171216996665\n2.3025893446351726\n2.296873353357001\n2.2958218344047037\n2.288737669165865\n2.2950496834414573\n2.2985210836443772\n2.306258172906896\n2.3054769108936184\n2.301259086494083\n2.2992779801825343\n2.2990364286514486\n2.307352820383829\n2.298271961139717\n2.2973928143280067\n2.303096107759361\n2.308475230380613\n2.2890142169941425\n2.3090867951043754\n2.304615639672382\n2.296458806821807\n2.3066671258869347\n2.297043431154291\n2.294482064970426\n2.284731147118264\n2.291115360465319\n2.297107017018198\n2.293386980781017\n2.2977169063774525\n2.303276174104917\n2.302389882105453\n2.306991778007295\n2.2832400126447445\n2.3107189719100902\n2.2887647526725563\n2.294203456629661\n2.310904921349405\n2.3044602712392113\n2.3005169009478483\n2.2992845033252927\n2.299811556603833\n2.2999844290542018\n2.3024703220882756\n2.298769621721513\n2.3012035856650215\n2.3056142093279517\n2.296084897685315\n2.2961082218400826\n2.309630171024544\n2.2919835906967005\n2.3042084467805823\n2.2979893104506917\n2.2967949850436544\n2.303069084673428\n2.2968561730171877\n2.2996243299346717\n2.302749904044714\n2.3039431596872744\n2.295690615446185\n2.3035245193211575\n2.2940084593596515\n2.3003146971146573\n2.3073898264727295\n2.313825068369818\n2.2938401010385845\n2.307545930414087\n2.3090542761103756\n2.295826601981018\n2.3073635982484135\n2.3165208761357334\n2.3006498629553254\n2.3078088906805063\n2.3109310924076754\n2.297297933232153\n2.300702245752688\n2.298291890956542\n2.295028568141577\n2.297151837326751\n2.3053650967294606\n2.3091406865673587\n2.295427570979302\n2.3030324099081585\n2.3071003833708708\n2.3003343604858117\n2.297814564698007\n2.304465164656685\n2.308948276647499\n2.3128314392182037\n2.3043166928786616\n2.2955060197463144\n2.301989411943705\n2.2989000948076725\n2.295442849313541\n2.3017749152686626\n2.301054327373671\n2.3020694332680276\n2.3064181933705523\n2.29691923196085\n2.2964347158718823\n2.305595173354032\n2.3035263316927677\n2.3003787402685334\n2.2960916137866536\n2.3004196975148523\n2.2992910615994937\n2.3007142061594545\n2.2942553685669025\n2.2902165460655475\n2.2916950201851396\n2.3018430087213364\n2.313500014921024\n2.301836494394864\n2.294181340122584\n2.289519134642086\n2.3059790287817616\n2.2990079280579767\n2.2998833508566325\n2.306422684448248\n2.299554467415511\n2.301666976142363\n2.307110912983539\n2.295620178560153\n2.298705097811153\n2.295841894127702\n2.3061758474360268\n2.2944776460172323\n2.30565353214303\n2.299111119918596\n2.3028969091090503\n2.300180370588884\n2.3073718153755776\n2.306262083264094\n2.30312789052705\n2.302104347916121\n2.3010975399218427\n2.297343397976992\n2.3044726602508256\n2.3017648823525945\n2.3084376864343414\n2.3013192273266783\n2.299698490981803\n2.2990815016678496\n2.3022767200164718\n2.304784725491508\n2.301029930161834\n2.305210557440885\n2.3010156092037635\n2.307107892821201\n2.302059965539525\n2.294543761606112\n2.3002835824854104\n2.3036747073436046\n2.3055871472564693\n2.3104230465857722\n2.298107952417474\n2.2974749837594346\n2.298942333098072\n2.2977330945741663\n2.3016588202649864\n2.3024538885783694\n2.3023586271101992\n2.3044690302595994\n2.2952055583696342\n2.2978509978435473\n2.300239516139147\n2.293411389175396\n2.3046210677496197\n2.306818768629131\n2.3115412825285273\n2.3104508326364477\n2.2993131871242913\n2.2941801504890162\n2.3048304115635734\n2.29359133914394\n2.308359845577993\n2.3034088610309666\n2.299988697650372\n2.2972666022060246\n2.300341578915464\n2.3071681166840743\n2.3003497421253263\n2.305067769904101\n2.298236544363638\n2.3049392746508848\n2.301570126741806\n2.303025954991735\n2.302075495321917\n2.29331752193942\n2.299343800157174\n2.300410856835397\n2.292880178919146\n2.2973966654773292\n2.3010254930205445\n2.309280189188139\n2.2964027332790224\n2.301864866674265\n2.299845343788773\n2.2926306265044314\n2.2932519862499463\n2.291846200385733\n2.2941256366297216\n2.299639422563389\n2.299637168069475\n2.29935127367873\n2.3062023560591625\n2.3008526077636686\n2.2994368815367086\n test acc | 0.115\n2.3033441646608095\n2.3142770508887933\n2.307196429597109\n2.2899497592429583\n2.3084757308534263\n2.293752635159913\n2.2991815091339762\n2.2955317694066655\n2.308414712814129\n2.301076126718969\n2.3034445027646884\n2.2957356708091403\n2.2933704649063578\n2.2987006106358994\n2.298140338559259\n2.303676284882927\n2.3052367468705874\n2.296306676986339\n2.3072758401845364\n2.2991906201161543\n2.2987681198767924\n2.294262454380693\n2.304978317346933\n2.3002595455962025\n2.290562924411623\n2.299578253420717\n2.3059776542701265\n2.298945461599276\n2.302422683982571\n2.3044850395346286\n2.2941075133146653\n2.303654233320764\n2.2989964310508335\n2.296792067242437\n2.29581439417868\n2.29551346509983\n2.307792903276534\n2.30462466703592\n2.306454180375211\n2.3021616507404072\n2.2974494675449275\n2.313701138484587\n2.3005630006671707\n2.3084206118444035\n2.291384744180088\n2.305569206307615\n2.3030992209006964\n2.2983991685138285\n2.2979960327979616\n2.287296884866636\n2.3120629548040252\n2.2985916232678236\n2.2995194052755217\n2.290941434834098\n2.300637891990772\n2.300460589720312\n2.30103885821014\n2.3093765895740974\n2.3077073471547815\n2.2920924373808957\n2.3012374562691438\n2.2866337307434588\n2.2957887870557703\n2.2945312218994145\n2.3048817687786745\n2.2995539507857536\n2.2915827312760313\n2.2958448483220737\n2.3096105004392458\n2.294304426440562\n2.2997581879418107\n2.309043992815926\n2.293159170679927\n2.3123110143478676\n2.300949651917895\n2.3085027206847424\n2.3039021702475626\n2.3007164797949318\n2.2948259577144206\n2.3006688499435417\n2.3026165539707995\n2.2977649574861614\n2.307259519483435\n2.2937987133101636\n2.3002608743373623\n2.2862825093468935\n2.297682975080887\n2.303975927590464\n2.3014019362151172\n2.2900477485776\n2.308403698353906\n2.3043420050551813\n2.2970141834903552\n2.3044213381305125\n2.3033617402764417\n2.315280351550878\n2.3033200613676486\n2.2994645998188945\n2.306582867494717\n2.3016565643371587\n2.298227298928315\n2.2940390936069726\n2.3056688599249835\n2.3018847716797572\n2.2904813278969582\n2.3018229319188896\n2.3088220376531154\n2.2994883839062266\n2.2967589822411383\n2.299651359316551\n2.3018027328370176\n2.301432025497868\n2.307726838799857\n2.30787552559908\n2.3027178950329072\n2.2960208992994238\n2.3034530390532595\n2.2991284391664313\n2.2977026316544897\n2.2971759887727496\n2.2962969887650493\n2.2994045395459204\n2.310498562806681\n2.3067453184764957\n2.2995786189713154\n2.295021987827214\n2.3041984681781402\n2.295162550732891\n2.307458252222449\n2.2980139953016203\n2.3051868350023628\n2.3041821296816365\n2.295396895521518\n2.3006667965698124\n2.3062927574676704\n2.30452071083885\n2.2977133942852688\n2.3051039073405395\n2.3043394639092862\n2.3040025228303396\n2.2962617702545756\n2.2974302215348006\n2.300956992763932\n2.3030467417778633\n2.2984003690732497\n2.2995336949915246\n2.3026007076585095\n2.295890864498193\n2.3012503049998654\n2.3003541202877464\n2.2999473177098166\n2.302896739891376\n2.2961810318144957\n2.301569663082325\n2.300390850367522\n2.3003872756273323\n2.306067190488938\n2.2957935668751404\n2.305352735158629\n2.3053409624823717\n2.295081785538463\n2.300309394803833\n2.2928693078284477\n2.3055188798802133\n2.304674040898663\n2.304262616891773\n2.3005877270366923\n2.302975980310841\n2.300589528244555\n2.2971036558816853\n2.2955542698942177\n2.30558253831471\n2.297794798267097\n2.303556625315054\n2.2984836245488105\n2.301904831589631\n2.298744611163138\n2.3047912826483627\n2.306914239001004\n2.3009790988563172\n2.294542794436302\n2.306849928266404\n2.3043220236483264\n2.294716255379373\n2.30397698015075\n2.3023985229113606\n2.3002766837525503\n2.2992481475011783\n2.3022688634797226\n2.309379895049969\n2.2965603337894995\n2.307933190955861\n2.300033525763394\n2.301833606531089\n2.296872428619803\n2.306700832901051\n2.3053008535546917\n2.305688268903624\n2.3050420083837038\n2.3010843664141634\n2.3073118018739707\n2.2997510252783213\n2.2949921454808635\n2.2976404880567687\n2.3075627615931533\n2.2959225740747327\n2.298158803483349\n2.2973668032183143\n2.3016108925276955\n2.3026804057439683\n2.30946167651592\n2.3111814643467006\n2.302918714839048\n2.299896370970623\n2.2943717326405624\n2.3010758410628\n2.3016880496741736\n2.3062903031886925\n2.301282656787231\n2.2992397683640764\n2.3025070461809913\n2.295800298517206\n2.2955351021294073\n2.299653291326109\n2.303691164569463\n2.3028338539761597\n2.29946225373109\n2.2883071329129274\n2.2942990792138023\n2.304754697465269\n2.2979715637068865\n2.296677899208673\n2.301988876821035\n2.297120983023832\n2.304593278019272\n2.2942537311954085\n2.308478300893466\n2.309969087527014\n2.2941771827130246\n2.3015980298494996\n2.3052045162586374\n2.2991909097869416\n2.3046476566544056\n2.301502341166125\n2.2936555693658125\n2.297993437761183\n2.3018552610547145\n2.305159489614577\n2.3007947552037216\n2.2989981705635407\n2.297747836257401\n2.3058041929400432\n2.2978872024986825\n2.3045374268482024\n2.295293095202358\n2.297567395814884\n2.305234111688126\n2.3023239327183314\n2.305261221929037\n2.297076120862543\n2.2946890877336896\n2.3004340631349005\n2.2975110911797385\n2.303458774914908\n2.3057150114340033\n2.2852282163030013\n2.294364971078468\n2.3094829190768915\n2.3032124789676023\n2.2960336700157558\n2.3038812637374213\n2.3011291189901057\n2.299081326848794\n2.293608679088572\n2.298915302124987\n2.3056275883253403\n2.3077717131170274\n2.3035339598698035\n2.301627597839029\n2.3058615262728113\n2.3051183071613397\n2.303394059943538\n2.301107486225856\n2.2975340281815337\n2.301649623925653\n2.298187337661585\n2.2975644482046786\n2.3032885473498474\n2.291143294258159\n2.2972130104660495\n2.304854183994947\n2.3021274187764043\n2.292315734313561\n2.3099794090703774\n2.3020181836630633\n2.3043769647146313\n2.309497745204386\n2.295045420950062\n2.299760297910765\n2.294903157018237\n2.2970969366738014\n2.3004846657968026\n2.3053899338767234\n2.301121674964131\n2.3051299552428772\n2.2972014573032267\n2.2920572083478783\n2.3048226909091905\n2.294787674624148\n2.3055043355305402\n2.3021507731662623\n2.2986746324913105\n2.298603393636911\n2.296958901196375\n2.2937746809365995\n2.2924070850161673\n2.2970546904326015\n2.3105852085047442\n2.2979516011433647\n2.307960967609324\n2.299253487257469\n2.2922173428860453\n2.306125790257772\n2.3000383764730303\n2.3064513137214937\n2.3002789005132014\n2.302219388526108\n2.289379747979061\n2.302260518586033\n2.290639474971775\n2.286226621144109\n2.2980703071041106\n2.293735868999903\n2.301320736859469\n2.2996047727143956\n2.305194409825221\n2.304410983474733\n2.291956567782881\n2.3063044036970815\n2.2988724372017715\n2.3143251196616417\n2.2834074586609203\n2.2972811478368635\n2.302526229041553\n2.3058463742174555\n2.2909059257576745\n2.303016710507597\n2.292736175408332\n2.2945168685000623\n2.287403122173779\n2.296346286203968\n2.3046615614987354\n2.303627776125717\n2.3089947491293574\n2.3047941953967266\n2.292391965560634\n2.29300390615762\n2.299281184225391\n2.3020561430506756\n2.305144960176633\n2.304276528245318\n2.300356374000698\n2.288171782996189\n2.2962874544690792\n2.295527312836015\n2.3066352275934943\n2.3050407033271076\n2.30191314333039\n2.2950501144948787\n2.305310855996435\n2.293422045156398\n2.305452897659581\n2.311017138226496\n2.292080295088711\n2.303202634785727\n2.302016632371229\n2.300185810142368\n2.306037904008308\n2.2988732445399744\n2.283672351508882\n2.307019671714973\n2.3146404881592018\n2.307448183859371\n2.299986254910247\n2.296848911763897\n2.294387394030251\n2.2958970073721603\n2.293077464606578\n2.2863310642623293\n2.3113155395614258\n2.3065307419412844\n2.2986514722812097\n2.295769481974808\n2.300931993104373\n2.301569918726615\n2.2907236655888834\n2.304463350767322\n2.3002546398010377\n2.3083531920998497\n2.294780202736141\n2.3040742124191906\n2.2975437550611204\n2.3068645996406048\n2.301666402943704\n2.301858141273888\n2.300988934325263\n2.3019928180477045\n2.2970848226110627\n2.30930279550739\n2.292085463537406\n2.3029718593835575\n2.298811155299119\n2.299365117201049\n2.3000770219754774\n2.2942404214719225\n2.3071517028764634\n2.2998943413028514\n2.293432621562865\n2.2995720521380427\n2.298180207496877\n2.2899519802717037\n2.2977545267123487\n2.3089729196090145\n2.3011706689637306\n2.3025900990192185\n2.2968745510044726\n2.295825255187409\n2.2887334722262143\n2.2950459168654733\n2.2985193024149915\n2.306257619228566\n2.305480499345543\n2.301255244398703\n2.2992764254759925\n2.299026683398596\n2.3073530420652735\n2.298273131825296\n2.2973907674546985\n2.3030959107509035\n2.3084766769456233\n2.2890101289387847\n2.309083059351912\n2.304613532852067\n2.296456505495391\n2.3066716440178103\n2.297037025412792\n2.2944705654703372\n2.2847330004222988\n2.2911111327291906\n2.297104919012997\n2.293381917714746\n2.297719952584458\n2.3032700988844015\n2.302385795958229\n2.3069901537408706\n2.2832352820434085\n2.310727271877772\n2.288759047241575\n2.2941976322963904\n2.3109137799843285\n2.3044544539444876\n2.300515775564979\n2.299282772034524\n2.2998143943767793\n2.2999847518815515\n2.3024711534625673\n2.298769261036415\n2.301200827565162\n2.30561506886652\n2.2960824063630407\n2.2961097583543517\n2.309633408763764\n2.2919737975143786\n2.304209555499534\n2.297983450928559\n2.2967948203427095\n2.303068661252624\n2.296854589431771\n2.299621696013126\n2.3027506404573184\n2.303938576679815\n2.2956892850978043\n2.3035243415435924\n2.29400762579921\n2.3003130323340133\n2.3073887680597\n2.313818928122448\n2.2938393844710236\n2.307540982417871\n2.3090522631228914\n2.2958257663230426\n2.3073601789731786\n2.3165207567400756\n2.300651315431095\n2.3078045383141945\n2.3109219434697725\n2.2972954697922385\n2.3007098578635623\n2.298289294822082\n2.295027556500319\n2.297153628048532\n2.3053586027711557\n2.309133402311716\n2.295431142891629\n2.303032068724703\n2.3070909978155623\n2.3003317037307682\n2.297820097963954\n2.3044575576072823\n2.308947923209034\n2.3128247569269025\n2.304319226942774\n2.295513342829995\n2.3019841070815734\n2.298903269382119\n2.2954402029413767\n2.301768758261638\n2.301051955125557\n2.302071810514949\n2.3064089032500785\n2.296921085774378\n2.2964372102524337\n2.305591411172969\n2.3035258234726785\n2.300378632842491\n2.296095421056225\n2.3004193621904996\n2.2992939315154057\n2.3007118655042906\n2.294250253591827\n2.290224112995444\n2.29169263819928\n2.3018423036073172\n2.3134935301146204\n2.3018367350554425\n2.2941858948384177\n2.2895212711628723\n2.3059796979728286\n2.299008034247967\n2.2998801302619047\n2.3064183167129304\n2.2995512364666784\n2.3016711786339785\n2.30710584185233\n2.295621946998802\n2.2987041528031655\n2.295840746951245\n2.3061816393556205\n2.2944784612044993\n2.3056548035435016\n2.2991088032413645\n2.302893063984408\n2.3001828181454993\n2.307372194346373\n2.3062569994731206\n2.3031284819175863\n2.302103187284869\n2.3010981491298055\n2.2973418128878613\n2.304474790642814\n2.3017620165852963\n2.3084370637834017\n2.3013209377456416\n2.29969640285381\n2.2990789057232393\n2.302274085480346\n2.304783960815066\n2.3010293715297916\n2.3052145888969005\n2.301017744319642\n2.307099739035589\n2.3020502052504552\n2.2945389456640126\n2.300282010723426\n2.3036804794313164\n2.305587021242001\n2.310417264216944\n2.298107872753668\n2.297477821727634\n2.298943225811394\n2.2977330869611894\n2.301656622338294\n2.3024539702704225\n2.3023629167490522\n2.304469796549092\n2.2952021034497996\n2.2978486740412816\n2.3002360068142464\n2.29341024920395\n2.3046162032409487\n2.306822524374151\n2.311537915072935\n2.3104504533760206\n2.2993052477129505\n2.294186605883022\n2.3048249623095405\n2.2935905185149945\n2.308343475808867\n2.3034077964623787\n2.299992075035787\n2.2972656971356797\n2.3003415291582856\n2.3071583627441834\n2.3003527443054885\n2.3050675599959747\n2.2982353016797026\n2.3049350756637126\n2.301571732873323\n2.3030254437927935\n2.302079934109065\n2.293294009052435\n2.2993436123069175\n2.3004132713166223\n2.2928759470488136\n2.2973879089298226\n2.3010279769347157\n2.3092848795229246\n2.2964036045542366\n2.3018646202989546\n2.2998447600689342\n2.292622772393817\n2.2932546779231613\n2.2918451006353497\n2.2941217268676444\n2.2996377317764782\n2.2996380979641784\n2.299347116207602\n2.3062051934307983\n2.3008556430132483\n2.2994362415654113\n test acc | 0.115\n"
    }
   ],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "test_acc_list = []\n",
    "epochs = 3\n",
    "step = int(train_size / batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx in range(step):\n",
    "        x_batch = x_train[batch_idx*batch_size:batch_idx*batch_size+batch_size]\n",
    "        y_batch = y_train[batch_idx*batch_size:batch_idx*batch_size+batch_size]\n",
    "        grad = network.gradient(x_batch, y_batch)\n",
    "\n",
    "\n",
    "        # 매개변수 갱신\n",
    "        for key in network.params.keys():\n",
    "            network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "        # 학습 경과 기록\n",
    "        loss = network.loss(x_batch, y_batch)\n",
    "        print(loss)\n",
    "    test_acc = network.accuracy(x_test, y_test)\n",
    "    test_acc_list.append(test_acc)\n",
    "    print(\" test acc | \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 후 파라미터 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 3 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"69.636527pt\" version=\"1.1\" viewBox=\"0 0 178.283234 69.636527\" width=\"178.283234pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 69.636527 \nL 178.283234 69.636527 \nL 178.283234 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 10.7 58.936527 \nL 62.436527 58.936527 \nL 62.436527 7.2 \nL 10.7 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p6b217c6966)\">\n    <image height=\"52\" id=\"image22092a82a9\" transform=\"scale(1 -1)translate(0 -52)\" width=\"52\" x=\"10.7\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAADQAAAA0CAYAAADFeBvrAAAABHNCSVQICAgIfAhkiAAAAI1JREFUaIHt10ENRSEMBdH255lACaJRgQM26OGLKIsJmSPgphNW5FrrRNHeuzoRERFzzvLG78IdKAbRGURnEJ1BdAbRGURnEN1zQXnOKX/wMvPGLVc890IG0RlEZxCdQXQG0RlEZxCdQXTfGKM80lq7cEpE77288dwLGURnEJ1BdAbRGURnEJ1BdM8F/QEx5g+KnNAVwwAAAABJRU5ErkJggg==\" y=\"-6.936527\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\"/>\n   <g id=\"matplotlib.axis_2\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 10.7 58.936527 \nL 10.7 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 62.436527 58.936527 \nL 62.436527 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 10.7 58.936527 \nL 62.436527 58.936527 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 10.7 7.2 \nL 62.436527 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 65.023353 58.936527 \nL 116.75988 58.936527 \nL 116.75988 7.2 \nL 65.023353 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pe3195bf875)\">\n    <image height=\"52\" id=\"image7fec9c10e4\" transform=\"scale(1 -1)translate(0 -52)\" width=\"52\" x=\"65.023353\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAADQAAAA0CAYAAADFeBvrAAAABHNCSVQICAgIfAhkiAAAAJVJREFUaIHt10ENBCEQBdGezRoAC9hBB6K4IgFP2NgV0XOokCoBP/3Ciaf3/otke+/sRERElFLSG58X7kAliJ4geoLoCaIniJ4geoLoXQd6xhjpD945541botaa3rjuhQTRE0RPED1B9ATRE0RPED1B9L6ttfTInPOFUyLWWumN615IED1B9ATRE0RPED1B9ATRuw70B0BQDdFXor6fAAAAAElFTkSuQmCC\" y=\"-6.936527\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\"/>\n   <g id=\"matplotlib.axis_4\"/>\n   <g id=\"patch_8\">\n    <path d=\"M 65.023353 58.936527 \nL 65.023353 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 116.75988 58.936527 \nL 116.75988 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 65.023353 58.936527 \nL 116.75988 58.936527 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 65.023353 7.2 \nL 116.75988 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g id=\"patch_12\">\n    <path d=\"M 119.346707 58.936527 \nL 171.083234 58.936527 \nL 171.083234 7.2 \nL 119.346707 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p18f432e993)\">\n    <image height=\"52\" id=\"image35978b941a\" transform=\"scale(1 -1)translate(0 -52)\" width=\"52\" x=\"119.346707\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAADQAAAA0CAYAAADFeBvrAAAABHNCSVQICAgIfAhkiAAAAJJJREFUaIHt2bENAyAMBVETZQV6dmYtGiZgChqaZAhTnNDdAF9+oqSstX6RrLWWnYiIiDlneuNz4Q5UgugJoieIniB6gugJoieI3nOgb601PVJKuXBKRO89vfHcCwmiJ4ieIHqC6AmiJ4ieIHqC6JUxRvpLcu9945Y456Q3nnshQfQE0RNETxA9QfQE0RNE7znQH2P5EgNdVNL/AAAAAElFTkSuQmCC\" y=\"-6.936527\"/>\n   </g>\n   <g id=\"matplotlib.axis_5\"/>\n   <g id=\"matplotlib.axis_6\"/>\n   <g id=\"patch_13\">\n    <path d=\"M 119.346707 58.936527 \nL 119.346707 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 171.083234 58.936527 \nL 171.083234 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 119.346707 58.936527 \nL 171.083234 58.936527 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 119.346707 7.2 \nL 171.083234 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p6b217c6966\">\n   <rect height=\"51.736527\" width=\"51.736527\" x=\"10.7\" y=\"7.2\"/>\n  </clipPath>\n  <clipPath id=\"pe3195bf875\">\n   <rect height=\"51.736527\" width=\"51.736527\" x=\"65.023353\" y=\"7.2\"/>\n  </clipPath>\n  <clipPath id=\"p18f432e993\">\n   <rect height=\"51.736527\" width=\"51.736527\" x=\"119.346707\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALIAAABFCAYAAADuHbzJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACR0lEQVR4nO3dO4oiYRSG4eMwgaCIFVRiMpi5g16BmalmbkFDcyNzlyCmIhia6BKMRUREEztV8YL/JF3NBN0Mcqrn8vE+kWCfU3/BixionQkhGPC/+/a3DwCkgZAhgZAhgZAhgZAhgZAh4fszf1woFEIcx64Lbrdb13wil8u55k+nk10ul8zbrhBFkWvfbrdzzSfK5bJ7x3q9fg0hxMViMZRKJdeux+PhPk9ae5bL5WsI4cMAnwo5jmPr9Xquw7Tbbdd84uXlxTU/m83eH0dRZK1Wy7Wv0+m45hPdbte9o9lsbszMSqWSDQYD167j8eg+j5nZ9Xp176hWq5vPnuOtBSQQMiQQMiQQMiQQMiQQMiQQMiQQMiQQMiQQMiQQMiQQMiQQMiQQMiQ89THOKIqsXq+7LthoNFzzifF4nMoeM7PL5WKr1cq1o1arpXKW6XSayh4zs2w2a5VKxbUjn8+ncpZ+v5/Kns/wigwJhAwJhAwJhAwJhAwJhAwJhAwJhAwJhAwJhAwJhAwJhAwJhAwJhAwJhAwJhAwJhAwJT31D5Hw+22KxcF1wOBy65hPz+dw1PxqN3h/fbjfb7/eufZPJxDWf8P5y/q/u97sdDgfXjrT+oai3m9/hFRkSCBkSCBkSCBkSCBkSCBkSCBkSCBkSCBkSCBkSCBkSCBkSCBkSCBkSCBkSCBkSMs98cDqTyRzMbPN1x/mjfoQQYjO5+zJ7uzfV+/roiadCBv5VvLWABEKGBEKGBEKGBEKGBEKGBEKGBEKGBEKGhJ+XLX+UOOk5zgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "######################################################################\n",
    "#  2-4 학습된 필터를 캡처하여 제출하세요                             #\n",
    "######################################################################\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}